Parfait Omr ğŸ˜„ ! On va faire **un portfolio GitHub clÃ© en main**, prÃªt Ã  copier-coller. Je te prÃ©pare **tous les README, mini datasets et pipelines Mermaid** pour tes 4 projets.

Tu nâ€™auras quâ€™Ã  crÃ©er ton repo `portfolio` et copier chaque dossier avec son contenu.

---

# **1ï¸âƒ£ README gÃ©nÃ©ral du repo `portfolio`**

`portfolio/README.md` :

```markdown
# Portfolio â€“ Rosette-MichÃ¨le Otounga

Bienvenue sur mon portfolio GitHub ! ğŸ‘©ğŸ½â€ğŸ’»

Je suis Ã©tudiante en Master Intelligence Artificielle et Data Scientist, avec expÃ©rience en **Big Data Engineering** et **Applied AI / ML**.

Ce repository prÃ©sente mes 4 projets phares :

1. **Vision + LLM (Ã‰valuation hallucinations)** â€“ IA appliquÃ©e / ML / Computer Vision
2. **Benchmarking Cosmos World Models** â€“ IA avancÃ©e / ML / Benchmarking
3. **Livraison de donnÃ©es Ã  RTE** â€“ Data Engineering / Data Delivery
4. **Automatisation panels Excel chez Renault** â€“ Data Engineering / Industrialisation

Chaque projet inclut :
- README clair et complet
- SchÃ©ma de pipeline Mermaid
- Mini dataset simulÃ©
- MÃ©thodologie et rÃ©sultats
```

---

# **2ï¸âƒ£ Projet : Vision + LLM (Ã‰valuation hallucinations)**

`portfolio/Vision_LLM/README.md` :

````markdown
# Vision + LLM (Ã‰valuation hallucinations)

## ğŸ“Œ Contexte
Projet IA appliquÃ©e pour Ã©valuer les hallucinations dâ€™un modÃ¨le multimodal Vision + LLM.
Objectif : fiabiliser les rÃ©ponses gÃ©nÃ©rÃ©es et analyser les limites du modÃ¨le.

## ğŸ§© ProblÃ©matique
Les LLM multimodaux peuvent produire des hallucinations ou erreurs factuelles.
DÃ©tecter et mesurer ces hallucinations est essentiel pour lâ€™usage en production.

## âš™ï¸ Pipeline / Architecture
```mermaid
graph LR
A[Images d'entrÃ©e] --> B[PrÃ©traitement]
B --> C[ModÃ¨le Recognize Anything + LLM]
C --> D[Sortie texte annotÃ©]
D --> E[Analyse hallucinations]
````

## ğŸ›  MÃ©thodologie

* PrÃ©traitement des images (normalisation, redimensionnement)
* GÃ©nÃ©ration de lÃ©gendes / rÃ©ponses avec LLM
* Ã‰valuation des hallucinations avec mÃ©triques automatisÃ©es (precision, recall)
* Comparaison entre modÃ¨les et rÃ©glage hyperparamÃ¨tres

## ğŸ“Š Dataset

* Mini dataset simulÃ© : 5 images fictives + descriptions CSV
* Colonnes : image_id, description_attendue

## ğŸ† RÃ©sultats / Livrables

* Tableau de mÃ©triques par image et modÃ¨le
* Graphiques : hallucinations les plus frÃ©quentes
* Impact : meilleure comprÃ©hension des limites du modÃ¨le

## âš ï¸ Limites / Perspectives

* Extension Ã  dâ€™autres types dâ€™images
* Automatisation de la correction des hallucinations

## ğŸ’¡ Recommandations / Next Steps

* IntÃ©grer module de validation humaine
* Industrialiser pipeline sur serveur/cloud

````

`portfolio/Vision_LLM/mini_dataset.csv` :

```csv
image_id,description_attendue
img1.jpg,"Un chat sur un canapÃ©"
img2.jpg,"Une voiture rouge sur la route"
img3.jpg,"Un chien qui joue avec une balle"
img4.jpg,"Un vÃ©lo devant une maison"
img5.jpg,"Une personne lisant un livre"
````

---

# **3ï¸âƒ£ Projet : Benchmarking Cosmos World Models**

`portfolio/Benchmarking_Cosmos/README.md` :

````markdown
# Benchmarking Cosmos World Models

## ğŸ“Œ Contexte
Projet avancÃ© de ML pour comparer des modÃ¨les de World Modeling.
Objectif : crÃ©er un pipeline automatisÃ© pour Ã©valuer la performance et la robustesse des modÃ¨les.

## ğŸ§© ProblÃ©matique
Les modÃ¨les de simulation doivent Ãªtre comparables de maniÃ¨re **reproductible et scalable**.
Besoin de mÃ©triques standardisÃ©es et de tests automatisÃ©s.

## âš™ï¸ Pipeline / Architecture
```mermaid
graph LR
A[ModÃ¨les Ã  tester] --> B[PrÃ©paration des jeux de donnÃ©es]
B --> C[ExÃ©cution automatique des modÃ¨les]
C --> D[Calcul des mÃ©triques comparatives]
D --> E[Tableau de benchmarking]
````

## ğŸ›  MÃ©thodologie

* Standardisation des datasets
* ExÃ©cution de plusieurs modÃ¨les avec mÃªmes entrÃ©es
* Calcul automatique des mÃ©triques (MAE, RMSE, etc.)
* GÃ©nÃ©ration de tableau comparatif et graphiques

## ğŸ“Š Dataset

* Mini dataset simulÃ© : 5 lignes avec colonnes features et target
* Colonnes : state, action, reward, next_state

## ğŸ† RÃ©sultats / Livrables

* Tableau de comparaison modÃ¨les
* Graphiques de performance
* Impact : industrialisation de lâ€™Ã©valuation et gain de temps

## âš ï¸ Limites / Perspectives

* Ajouter plus de modÃ¨les
* Ã‰tendre aux datasets rÃ©els

## ğŸ’¡ Recommandations / Next Steps

* Pipeline entiÃ¨rement scalable sur serveur/cloud
* IntÃ©gration dans CI/CD pour tests rÃ©guliers

````

`portfolio/Benchmarking_Cosmos/mini_dataset.csv` :

```csv
state,action,reward,next_state
s1,a1,1,s2
s2,a2,0,s3
s3,a1,1,s4
s4,a2,0,s5
s5,a1,1,s1
````

---

# **4ï¸âƒ£ Projet : Livraison de donnÃ©es Ã  RTE**

`portfolio/Livraison_RTE/README.md` :

````markdown
# Livraison de donnÃ©es Ã  RTE

## ğŸ“Œ Contexte
Projet Data Engineering pour transformer et livrer des datasets fiables Ã  RTE.
Objectif : traduire les besoins mÃ©tier en pipeline SQL opÃ©rationnel.

## ğŸ§© ProblÃ©matique
Les Ã©quipes mÃ©tier ont besoin de donnÃ©es fiables et Ã  jour.
Besoin dâ€™un pipeline automatisÃ© pour Ã©viter erreurs manuelles.

## âš™ï¸ Pipeline / Architecture
```mermaid
graph LR
A[RequÃªte mÃ©tier] --> B[Extraction SQL]
B --> C[Transformation / nettoyage]
C --> D[Validation des donnÃ©es]
D --> E[Livraison dataset final]
````

## ğŸ›  MÃ©thodologie

* Analyse des besoins mÃ©tier
* CrÃ©ation de scripts SQL pour extraction et transformation
* VÃ©rification des donnÃ©es (contrÃ´les qualitÃ©)
* Livraison des datasets prÃªts Ã  lâ€™usage

## ğŸ“Š Dataset

* Mini dataset simulÃ© : 5 lignes
* Colonnes : timestamp, voltage, current, power

## ğŸ† RÃ©sultats / Livrables

* Dataset fiable livrÃ© aux Ã©quipes mÃ©tier
* Process automatisÃ©
* Impact : gain de temps et rÃ©duction des erreurs

## âš ï¸ Limites / Perspectives

* Industrialiser pour dâ€™autres dÃ©partements
* Ajout de monitoring automatique

## ğŸ’¡ Recommandations / Next Steps

* IntÃ©gration pipeline dans orchestration type Airflow

````

`portfolio/Livraison_RTE/mini_dataset.csv` :

```csv
timestamp,voltage,current,power
2025-01-01 00:00,230,5,1150
2025-01-01 01:00,231,4,924
2025-01-01 02:00,229,6,1374
2025-01-01 03:00,232,5,1160
2025-01-01 04:00,230,4,920
````

---

# **5ï¸âƒ£ Projet : Automatisation panels Excel chez Renault**

`portfolio/Automatisation_Excel_Renault/README.md` :

````markdown
# Automatisation panels Excel chez Renault

## ğŸ“Œ Contexte
Optimisation dâ€™un workflow Excel pour Renault.
Objectif : rÃ©duire erreurs et temps passÃ© Ã  manipuler manuellement les panels.

## ğŸ§© ProblÃ©matique
Workflow manuel sur Excel : rÃ©pÃ©titif, source dâ€™erreurs.
Besoin dâ€™un script ou macro pour industrialiser le process.

## âš™ï¸ Pipeline / Architecture
```mermaid
graph LR
A[Fichiers Excel bruts] --> B[Macro / Script VBA]
B --> C[Nettoyage & calculs automatiques]
C --> D[Panels consolidÃ©s prÃªts]
```
````

## ğŸ›  MÃ©thodologie

* Analyse des panels existants
* Script VBA pour automatiser nettoyages, calculs et tableaux
* Test et validation des rÃ©sultats sur mini dataset simulÃ©

## ğŸ“Š Dataset

* Mini panel Excel : 5 lignes
* Colonnes : date, vÃ©hicule, consommation, distance, CO2

## ğŸ† RÃ©sultats / Livrables

* Panels consolidÃ©s automatisÃ©s
* RÃ©duction des erreurs et du temps de traitement
* Impact : workflow optimisÃ© et industrialisÃ©

## âš ï¸ Limites / Perspectives

* Ajouter plus de rÃ¨gles mÃ©tier

