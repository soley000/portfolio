# Vision + LLM (Ã‰valuation hallucinations)

## ðŸ“Œ Contexte
Projet IA appliquÃ©e pour Ã©valuer les hallucinations dâ€™un modÃ¨le multimodal Vision + LLM.
Objectif : fiabiliser les rÃ©ponses gÃ©nÃ©rÃ©es et analyser les limites du modÃ¨le.

## ðŸ§© ProblÃ©matique
Les LLM multimodaux peuvent produire des hallucinations ou erreurs factuelles.
DÃ©tecter et mesurer ces hallucinations est essentiel pour lâ€™usage en production.

## âš™ï¸ Pipeline / Architecture
```mermaid
graph LR
A[Images d'entrÃ©e] --> B[PrÃ©traitement]
B --> C[ModÃ¨le Recognize Anything + LLM]
C --> D[Sortie texte annotÃ©]
D --> E[Analyse hallucinations]
